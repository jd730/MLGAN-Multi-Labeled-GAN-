21,22c21
<          input_fname_pattern='*.jpg', checkpoint_dir=None, sample_dir=None,
<          label1_dim=None, label2_dim = None, label1_path= None, label2_path = None):
---
>          input_fname_pattern='*.jpg', checkpoint_dir=None, sample_dir=None):
35,36d33
<       label1_dim: (optional) Dimension of dim for label1. [None]
<       label2_dim: (optional) Dimension of dim for label2. [None]
58,62d54
<     self.label1_dim = label1_dim
<     self.label2_dim = label2_dim
<     self.label1_path = label1_path
<     self.label2_path = label2_path
< 
85d76
<       print os.path.join("./data", self.dataset_name, self.input_fname_pattern)
92,96d82
<     #jaed
<     if self.label1_dim : # key : id, value : stlye or gerne
<         self.label1_dic, self.label1_original = get_label(self.label1_path)
<     if self.label2_dim :
<         self.label2_dic, self.label2_original = get_label(self.label2_path)
108,117d93
<     if self.label1_dim : 
<       self.label1 = tf.placeholder(tf.float32,[self.batch_size,self.label1_dim], name='label1')
<     else :
<       self.label1 = None
<     
<     if self.label2_dim :
<       self.label2 = tf.placeholder(tf.float32,[self.batch_size,self.label2_dim], name='label2')
<     else :
<       self.label2 = None
< 
131a108,116
>     self.G                  = self.generator(self.z, self.y)
>     self.D, self.D_logits   = self.discriminator(inputs, self.y, reuse=False)
>     self.sampler            = self.sampler(self.z, self.y)
>     self.D_, self.D_logits_ = self.discriminator(self.G, self.y, reuse=True)
>     
>     self.d_sum = histogram_summary("d", self.D)
>     self.d__sum = histogram_summary("d_", self.D_)
>     self.G_sum = image_summary("G", self.G)
> 
137,174d121
<     def softmax_cross_entropy_with_logits(x,y):
<       try :
<         return tf.nn.softmax_cross_entropy_with_logits(logits=x, labels=y)
<       except:
<         return tf.nn.softmax_cross_entropy_with_logits(logits=x, targets=y)
< 
<     if not self.label1_dim :
<       self.G                  = self.generator(self.z, self.y)
<       self.D, self.D_logits   = self.discriminator(inputs, self.y, reuse=False)
<       self.sampler            = self.sampler(self.z, self.y)
<       self.D_, self.D_logits_  = self.discriminator(self.G, self.y, reuse=True)
<     
<     elif not self.label2_dim:
<       self.G                  = self.generator(self.z, self.y)
<       self.D, self.D_logits, self.Dl1, self.Dl1_logits  = self.discriminator(inputs, self.y, reuse=False)
<       self.sampler            = self.sampler(self.z, self.y)
<       self.D_, self.D_logits_, self.Dl1_, self.Dl1_logits_,  = self.discriminator(self.G, self.y, reuse=True)
<       self.dl1_sum = histogram_summary("d_l1", self.Dl1)
<       self.dl1__sum = histogram_summary("d_l1_", self.Dl1_)
<     else :
<       self.G                  = self.generator(self.z, self.y)
< #      self.D, self.D_logits, self.Dl1, self.Dl1_logits, self.Dl2, self.Dl2_logits   = self.discriminator(inputs, self.y, reuse=False)
<       self.D, self.D_logits = self.discriminator(inputs, self.y, reuse=False)
<       self.sampler            = self.sampler(self.z, self.y, self.label1, self.label2)
<       self.D_, self.D_logits_ = self.discriminator(self.G, self.y, reuse=True)
< #      self.dl1_sum = histogram_summary("d_l1", self.Dl1)
< #      self.dl2_sum = histogram_summary("d_l2", self.Dl2)
< #      self.dl1__sum = histogram_summary("d_l1_", self.Dl1_)
< #      self.dl2__sum = histogram_summary("d_l2_", self.Dl2_)
< 
< #      self.dl1_loss_real = tf.reduce_mean(softmax_cross_entropy_with_logits(self.Dl1_logits,self.label1*0.9)) # .9 is smoothing
< #      self.dl2_loss_real = tf.reduce_mean(softmax_cross_entropy_with_logits(self.Dl2_logits,self.label2*0.9))
< #      self.dl1_loss_fake = tf.reduce_mean(softmax_cross_entropy_with_logits(self.Dl1_logits_,(1.0/self.label1_dim) * tf.ones_like(self.label1)))
< #      self.dl2_loss_fake = tf.reduce_mean(softmax_cross_entropy_with_logits(self.Dl2_logits_,(1.0/self.label2_dim) * tf.ones_like(self.label2)))
< 
<     self.d_sum = histogram_summary("d", self.D)
<     self.d__sum = histogram_summary("d_", self.D_)
<     self.G_sum = image_summary("G", self.G)
179,180c126,127
<       sigmoid_cross_entropy_with_logits(self.D_logits_, tf.zeros_like(self.D_))) # zeros
<     self.g_loss_image = tf.reduce_mean(
---
>       sigmoid_cross_entropy_with_logits(self.D_logits_, tf.zeros_like(self.D_)))
>     self.g_loss = tf.reduce_mean(
185,194c132,134
<     print self.label2_dim
<     if self.label2_dim :
< #      self.dl_loss_real_sum = scalar_summary("d_l_loss_real", self.dl1_loss_real + self.dl2_loss_real)                      
< #      self.dl_loss_fake_sum = scalar_summary("d_l_loss_fake", self.dl1_loss_fake + self.dl2_loss_fake)
<       self.d_loss = self.d_loss_real + self.d_loss_fake #+ (self.dl1_loss_real + self.dl2_loss_real)*0.00001
<       self.g_loss = self.g_loss_image# - (self.dl1_loss_fake + self.dl2_loss_fake)*0.00001
<     else :
<       self.d_loss = self.d_loss_real + self.d_loss_fake
<       self.g_loss = self.g_loss_image
<     
---
>                           
>     self.d_loss = self.d_loss_real + self.d_loss_fake
> 
218c158
<         [self.z_sum, self.d_sum, self.d_loss_real_sum, self.d_loss_sum])#, self.dl_loss_real_sum, self.dl_loss_fake_sum])
---
>         [self.z_sum, self.d_sum, self.d_loss_real_sum, self.d_loss_sum])
222,223c162
< #    sample_z = np.random.normal(0,1, size=(self.sample_num, self.z_dim))
< 
---
>     
273,284d211
<           
<           if self.label1_dim : #batch_file is image
<             batch_label1s = [self.label1_dic[   batch_file.split('/')[-1].split('.')[0] ] for batch_file in batch_files]
<             batch_label1s = one_hot(batch_label1s, self.label1_dim)
<           else :
<             batch_label1s = None
<           if self.label2_dim :
<             batch_label2s = [self.label2_dic[   batch_file.split('/')[-1].split('.')[0] ] for batch_file in batch_files] 
<             batch_label2s = one_hot(batch_label2s, self.label2_dim)
<           else : 
<             batch_label2s = None
< 
287c214
<           else: 
---
>           else:
328,329c255,256
<         elif self.label2_dim: 
<            # Update D network
---
>         else:
>           # Update D network
331,332c258
<             feed_dict={ self.inputs: batch_images, self.z: batch_z,
<                 self.label1: batch_label1s, self.label2: batch_label2s})
---
>             feed_dict={ self.inputs: batch_images, self.z: batch_z })
337c263
<             feed_dict={ self.z: batch_z, self.label1: batch_label1s, self.label2: batch_label2s })
---
>             feed_dict={ self.z: batch_z })
342c268
<             feed_dict={ self.z: batch_z, self.label1: batch_label1s, self.label2: batch_label2s})
---
>             feed_dict={ self.z: batch_z })
345,365c271
<           errD_fake = self.d_loss_fake.eval({ self.z: batch_z, self.label1: batch_label1s, self.label2: batch_label2s })
<           errD_real = self.d_loss_real.eval({ self.inputs: batch_images, self.label1: batch_label1s, self.label2: batch_label2s })
<           errG = self.g_loss.eval({self.z: batch_z, self.label1: batch_label1s, self.label2: batch_label2s})
< #          errDl1_fake = self.dl1_loss_fake.eval({self.z: batch_z, self.label1: batch_label1s, self.label2: batch_label2s})
< #          errDl2_fake = self.dl2_loss_fake.eval({self.z: batch_z, self.label1: batch_label1s, self.label2: batch_label2s})
< #          errDl1_real = self.dl1_loss_real.eval({ self.inputs: batch_images, self.label1: batch_label1s, self.label2: batch_label2s })
< #          errDl2_real = self.dl2_loss_real.eval({ self.inputs: batch_images, self.label1: batch_label1s, self.label2: batch_label2s })
<         else: 
<            # Update D network
<           _, summary_str = self.sess.run([d_optim, self.d_sum],feed_dict={ self.inputs: batch_images, self.z: batch_z})
<           self.writer.add_summary(summary_str, counter)
< 
<           # Update G network
<           _, summary_str = self.sess.run([g_optim, self.g_sum], feed_dict={ self.z: batch_z})
<           self.writer.add_summary(summary_str, counter)
< 
<           # Run g_optim twice to make sure that d_loss does not go to zero (different from paper)
<           _, summary_str = self.sess.run([g_optim, self.g_sum],feed_dict={ self.z: batch_z})
<           self.writer.add_summary(summary_str, counter)
<           
<           errD_fake = self.d_loss_fake.eval({ self.z: batch_z})
---
>           errD_fake = self.d_loss_fake.eval({ self.z: batch_z })
368d273
<           
374,375c279
< #        if self.label2_dim :
< #          print (errDl1_real, errDl2_real, errDl1_fake, errDl2_fake)
---
> 
389c293
<           elif self.label2_dim:
---
>           else:
396,397d299
<                     self.label1:batch_label1s,
<                     self.label2:batch_label2s
405,419d306
<           else :
<             try:
<               samples, d_loss, g_loss = self.sess.run(
<                 [self.sampler, self.d_loss, self.g_loss],
<                 feed_dict={
<                     self.z: sample_z,
<                     self.inputs: sample_inputs,
<                 },
<               )
<               save_images(samples, image_manifold_size(samples.shape[0]),
<                     './{}/train_{:02d}_{:04d}.png'.format(config.sample_dir, epoch, idx))
<               print("[Sample] d_loss: %.8f, g_loss: %.8f" % (d_loss, g_loss)) 
<             except:
<               print("one pic error!...")
< 
423c310
<   
---
> 
428,429c315,324
<       print("discriminator")
<       if self.y_dim:
---
> 
>       if not self.y_dim:
>         h0 = lrelu(conv2d(image, self.df_dim, name='d_h0_conv'))
>         h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*2, name='d_h1_conv')))
>         h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim*4, name='d_h2_conv')))
>         h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim*8, name='d_h3_conv')))
>         h4 = linear(tf.reshape(h3, [self.batch_size, -1]), 1, 'd_h4_lin')
> 
>         return tf.nn.sigmoid(h4), h4
>       else:
431a327
> 
433a330
> 
436a334
>         
438a337
> 
440,464d338
<         return tf.nn.sigmoid(h3), h3
<       elif not self.label1_dim:
<         h0 = lrelu(conv2d(image, self.df_dim, name='d_h0_conv'))
<         h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*2, name='d_h1_conv')))
<         h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim*4, name='d_h2_conv')))
<         h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim*8, name='d_h3_conv')))
<         h4 = linear(tf.reshape(h3, [self.batch_size, -1]), 1, 'd_h4_lin')
<         return tf.nn.sigmoid(h4), h4
<       elif not self.label2_dim:
<         h0 = lrelu(conv2d(image, self.df_dim, name='d_h0_conv'))
<         h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*2, name='d_h1_conv')))
<         h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim*4, name='d_h2_conv')))
<         h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim*8, name='d_h3_conv')))
<         h4 = linear(tf.reshape(h3, [self.batch_size, -1]), 1, 'd_h4_lin')
<         return tf.nn.sigmoid(h4), h4
<  
<       else: #label1 and label2 are on
<         label1 = tf.reshape(self.label1, [self.batch_size, 1, 1, self.label1_dim])
<         x = conv_cond_concat(image, label1)
<         label2 = tf.reshape(self.label2, [self.batch_size, 1, 1, self.label2_dim])
<         x = conv_cond_concat(x, label2)
<         h0 = lrelu(conv2d(x, self.df_dim, name='d_h0_conv'))
<         h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*2, name='d_h1_conv')))
<         h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim*4, name='d_h2_conv')))
<         h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim*8, name='d_h3_conv')))
466,475c340
<         h3_reshape = tf.reshape(h3, [self.batch_size, -1])
<         h4 = linear(h3_reshape,1, 'd_h4_lin')
<         
< #        hf0 = lrelu(linear(h3_reshape,1024 , 'd_hf0_lin'))
< #        hf1 = lrelu(linear(hf0, 512 , 'd_hf1_lin'))
< #        hf2 = lrelu(linear(hf1, self.label1_dim , 'd_hf2_lin'))
< #        hs0 = lrelu(linear(h3_reshape,1024 , 'd_hs0_lin'))
< #        hs1 = lrelu(linear(hs0, 512 , 'd_hs1_lin'))
< #        hs2 = lrelu(linear(hs1, self.label2_dim , 'd_hs2_lin'))
<         return tf.nn.sigmoid(h4), h4#, tf.nn.softmax(hf2),hf2, tf.nn.softmax(hs2), hs2  
---
>         return tf.nn.sigmoid(h3), h3
479,504c344
<       if self.y_dim:
<         s_h, s_w = self.output_height, self.output_width
<         s_h2, s_h4 = int(s_h/2), int(s_h/4)
<         s_w2, s_w4 = int(s_w/2), int(s_w/4)
< 
<         # yb = tf.expand_dims(tf.expand_dims(y, 1),2)
<         yb = tf.reshape(y, [self.batch_size, 1, 1, self.y_dim])
<         z = concat([z, y], 1)
<         print np.shape(z)
< 
<         h0 = tf.nn.relu(
<             self.g_bn0(linear(z, self.gfc_dim, 'g_h0_lin')))
<         h0 = concat([h0, y], 1)
< 
<         h1 = tf.nn.relu(self.g_bn1(
<             linear(h0, self.gf_dim*2*s_h4*s_w4, 'g_h1_lin')))
<         h1 = tf.reshape(h1, [self.batch_size, s_h4, s_w4, self.gf_dim * 2])
< 
<         h1 = conv_cond_concat(h1, yb)
< 
<         h2 = tf.nn.relu(self.g_bn2(deconv2d(h1,
<             [self.batch_size, s_h2, s_w2, self.gf_dim * 2], name='g_h2')))
<         h2 = conv_cond_concat(h2, yb)
<         return tf.nn.sigmoid(
<            deconv2d(h2, [self.batch_size, s_h, s_w, self.c_dim], name='g_h3'))
<       elif not self.label1_dim:
---
>       if not self.y_dim:
510,517d349
<         
<         # project `z` and reshape
<         self.z_, self.h0_w, self.h0_b = linear(
<             z, self.gf_dim*8*s_h16*s_w16, 'g_h0_lin', with_w=True)
< 
<         self.h0 = tf.reshape(
<             self.z_, [-1, s_h16, s_w16, self.gf_dim * 8])
<         h0 = tf.nn.relu(self.g_bn0(self.h0))
519,576d350
<         self.h1, self.h1_w, self.h1_b = deconv2d(
<             h0, [self.batch_size, s_h8, s_w8, self.gf_dim*4], name='g_h1', with_w=True)
<         h1 = tf.nn.relu(self.g_bn1(self.h1))
< 
<         h2, self.h2_w, self.h2_b = deconv2d(
<             h1, [self.batch_size, s_h4, s_w4, self.gf_dim*2], name='g_h2', with_w=True)
<         h2 = tf.nn.relu(self.g_bn2(h2))
< 
<         h3, self.h3_w, self.h3_b = deconv2d(
<             h2, [self.batch_size, s_h2, s_w2, self.gf_dim*1], name='g_h3', with_w=True)
<         h3 = tf.nn.relu(self.g_bn3(h3))
< 
<         h4, self.h4_w, self.h4_b = deconv2d(
<             h3, [self.batch_size, s_h, s_w, self.c_dim], name='g_h4', with_w=True)
<         return tf.nn.tanh(h4)
<       elif not self.label2_dim:
<         s_h, s_w = self.output_height, self.output_width
<         s_h2, s_w2 = conv_out_size_same(s_h, 2), conv_out_size_same(s_w, 2)
<         s_h4, s_w4 = conv_out_size_same(s_h2, 2), conv_out_size_same(s_w2, 2)
<         s_h8, s_w8 = conv_out_size_same(s_h4, 2), conv_out_size_same(s_w4, 2)
<         s_h16, s_w16 = conv_out_size_same(s_h8, 2), conv_out_size_same(s_w8, 2)
<        # project `z` and reshape
<         self.z_, self.h0_w, self.h0_b = linear(
<             z, self.gf_dim*8*s_h16*s_w16, 'g_h0_lin', with_w=True)
< 
<         self.h0 = tf.reshape(
<             self.z_, [-1, s_h16, s_w16, self.gf_dim * 8])
<         h0 = tf.nn.relu(self.g_bn0(self.h0))
< 
<         self.h1, self.h1_w, self.h1_b = deconv2d(
<             h0, [self.batch_size, s_h8, s_w8, self.gf_dim*4], name='g_h1', with_w=True)
<         h1 = tf.nn.relu(self.g_bn1(self.h1))
< 
<         h2, self.h2_w, self.h2_b = deconv2d(
<             h1, [self.batch_size, s_h4, s_w4, self.gf_dim*2], name='g_h2', with_w=True)
<         h2 = tf.nn.relu(self.g_bn2(h2))
< 
<         h3, self.h3_w, self.h3_b = deconv2d(
<             h2, [self.batch_size, s_h2, s_w2, self.gf_dim*1], name='g_h3', with_w=True)
<         h3 = tf.nn.relu(self.g_bn3(h3))
< 
<         h4, self.h4_w, self.h4_b = deconv2d(
<             h3, [self.batch_size, s_h, s_w, self.c_dim], name='g_h4', with_w=True)
<         return tf.nn.tanh(h4)
<       else: # label1 and label2 are on
<         # three image merge which first from z, second from label1, third from label2
<         s_h, s_w = self.output_height, self.output_width
<         s_h2, s_w2 = conv_out_size_same(s_h, 2), conv_out_size_same(s_w, 2)
<         s_h4, s_w4 = conv_out_size_same(s_h2, 2), conv_out_size_same(s_w2, 2)
<         s_h8, s_w8 = conv_out_size_same(s_h4, 2), conv_out_size_same(s_w4, 2)
<         s_h16, s_w16 = conv_out_size_same(s_h8, 2), conv_out_size_same(s_w8, 2)
<        # tiled_label1 = tf.tile(self.label1, int(self.z_dim/self.label1_dim))
<        # tiled_label2 = tf.tile(self.label2, int(self.z_dim/self.label2_dim))
<         #print np.shape(tiled_label1)
< #        tiled_label1 = self.label1
< #        tiled_label2 = self.label2
<  #       z = concat([z,tiled_label1,tiled_label2],1)
<  
599,602d372
<         return tf.nn.tanh(h4)
< 
< 
< 
604,607c374,375
<   def sampler(self, z, y=None, label1=None, label2=None):
<     with tf.variable_scope("generator") as scope:
<       scope.reuse_variables()
<       if self.y_dim :
---
>         return tf.nn.tanh(h4)
>       else:
612c380
<         # yb = tf.reshape(y, [-1, 1, 1, self.y_dim])
---
>         # yb = tf.expand_dims(tf.expand_dims(y, 1),2)
616c384,385
<         h0 = tf.nn.relu(self.g_bn0(linear(z, self.gfc_dim, 'g_h0_lin'), train=False))
---
>         h0 = tf.nn.relu(
>             self.g_bn0(linear(z, self.gfc_dim, 'g_h0_lin')))
620c389
<             linear(h0, self.gf_dim*2*s_h4*s_w4, 'g_h1_lin'), train=False))
---
>             linear(h0, self.gf_dim*2*s_h4*s_w4, 'g_h1_lin')))
621a391
> 
624,625c394,395
<         h2 = tf.nn.relu(self.g_bn2(
<             deconv2d(h1, [self.batch_size, s_h2, s_w2, self.gf_dim * 2], name='g_h2'), train=False))
---
>         h2 = tf.nn.relu(self.g_bn2(deconv2d(h1,
>             [self.batch_size, s_h2, s_w2, self.gf_dim * 2], name='g_h2')))
628,648c398,405
<         return tf.nn.sigmoid(deconv2d(h2, [self.batch_size, s_h, s_w, self.c_dim], name='g_h3'))
<       elif not self.label1_dim: # no y, label1, label2
<         s_h, s_w = self.output_height, self.output_width
<         s_h2, s_w2 = conv_out_size_same(s_h, 2), conv_out_size_same(s_w, 2)
<         s_h4, s_w4 = conv_out_size_same(s_h2, 2), conv_out_size_same(s_w2, 2)
<         s_h8, s_w8 = conv_out_size_same(s_h4, 2), conv_out_size_same(s_w4, 2)
<         s_h16, s_w16 = conv_out_size_same(s_h8, 2), conv_out_size_same(s_w8, 2)
<         # project `z` and reshape
<         h0 = tf.reshape(
<             linear(z, self.gf_dim*8*s_h16*s_w16, 'g_h0_lin'),
<             [-1, s_h16, s_w16, self.gf_dim * 8])
<         h0 = tf.nn.relu(self.g_bn0(h0, train=False))
<         h1 = deconv2d(h0, [self.batch_size, s_h8, s_w8, self.gf_dim*4], name='g_h1')
<         h1 = tf.nn.relu(self.g_bn1(h1, train=False))
<         h2 = deconv2d(h1, [self.batch_size, s_h4, s_w4, self.gf_dim*2], name='g_h2')
<         h2 = tf.nn.relu(self.g_bn2(h2, train=False))
<         h3 = deconv2d(h2, [self.batch_size, s_h2, s_w2, self.gf_dim*1], name='g_h3')
<         h3 = tf.nn.relu(self.g_bn3(h3, train=False))
<         h4 = deconv2d(h3, [self.batch_size, s_h, s_w, self.c_dim], name='g_h4')
<         return tf.nn.tanh(h4)
<       elif not self.label2_dim:
---
>         return tf.nn.sigmoid(
>             deconv2d(h2, [self.batch_size, s_h, s_w, self.c_dim], name='g_h3'))
> 
>   def sampler(self, z, y=None):
>     with tf.variable_scope("generator") as scope:
>       scope.reuse_variables()
> 
>       if not self.y_dim:
670a428
> 
674,677c432,433
<         s_h2, s_w2 = conv_out_size_same(s_h, 2), conv_out_size_same(s_w, 2)
<         s_h4, s_w4 = conv_out_size_same(s_h2, 2), conv_out_size_same(s_w2, 2)
<         s_h8, s_w8 = conv_out_size_same(s_h4, 2), conv_out_size_same(s_w4, 2)
<         s_h16, s_w16 = conv_out_size_same(s_h8, 2), conv_out_size_same(s_w8, 2)
---
>         s_h2, s_h4 = int(s_h/2), int(s_h/4)
>         s_w2, s_w4 = int(s_w/2), int(s_w/4)
679,686c435,437
<    #     tiled_label1 = label1
<    #     tiled_label2 = label2
<    #     z = concat([z,tiled_label1,tiled_label2],1)
<         # project `z` and reshape
<         h0 = tf.reshape(
<             linear(z, self.gf_dim*8*s_h16*s_w16, 'g_h0_lin'),
<             [-1, s_h16, s_w16, self.gf_dim * 8])
<         h0 = tf.nn.relu(self.g_bn0(h0, train=False))
---
>         # yb = tf.reshape(y, [-1, 1, 1, self.y_dim])
>         yb = tf.reshape(y, [self.batch_size, 1, 1, self.y_dim])
>         z = concat([z, y], 1)
688,689c439,440
<         h1 = deconv2d(h0, [self.batch_size, s_h8, s_w8, self.gf_dim*4], name='g_h1')
<         h1 = tf.nn.relu(self.g_bn1(h1, train=False))
---
>         h0 = tf.nn.relu(self.g_bn0(linear(z, self.gfc_dim, 'g_h0_lin'), train=False))
>         h0 = concat([h0, y], 1)
691,692c442,445
<         h2 = deconv2d(h1, [self.batch_size, s_h4, s_w4, self.gf_dim*2], name='g_h2')
<         h2 = tf.nn.relu(self.g_bn2(h2, train=False))
---
>         h1 = tf.nn.relu(self.g_bn1(
>             linear(h0, self.gf_dim*2*s_h4*s_w4, 'g_h1_lin'), train=False))
>         h1 = tf.reshape(h1, [self.batch_size, s_h4, s_w4, self.gf_dim * 2])
>         h1 = conv_cond_concat(h1, yb)
694,695c447,449
<         h3 = deconv2d(h2, [self.batch_size, s_h2, s_w2, self.gf_dim*1], name='g_h3')
<         h3 = tf.nn.relu(self.g_bn3(h3, train=False))
---
>         h2 = tf.nn.relu(self.g_bn2(
>             deconv2d(h1, [self.batch_size, s_h2, s_w2, self.gf_dim * 2], name='g_h2'), train=False))
>         h2 = conv_cond_concat(h2, yb)
697,698c451
<         h4 = deconv2d(h3, [self.batch_size, s_h, s_w, self.c_dim], name='g_h4')
<         return tf.nn.tanh(h4) 
---
>         return tf.nn.sigmoid(deconv2d(h2, [self.batch_size, s_h, s_w, self.c_dim], name='g_h3'))
